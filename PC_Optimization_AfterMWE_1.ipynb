{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTe8YVSIMTS9qRVX8Y9F5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nozasp/PredictiveCoding/blob/main/PC_Optimization_AfterMWE_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "!pip install icecream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgKrvSpapxwW",
        "outputId": "26fa21cd-8816-4942-f160-0b8dd0a68d9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu118)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4133 sha256=b039f52fcf2438113dd4f30fc0bb49849cfaad8fcfa3d715a22c6ba5bfd21d13\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting colorama>=0.3.9 (from icecream)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Collecting executing>=0.3.1 (from icecream)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 icecream-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "leIifZGpEdAL",
        "outputId": "494bed2f-dead-4a06-8d30-48e1984a3d67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-279713c6-8a2a-4e85-ab8f-feaa3e0b96ad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-279713c6-8a2a-4e85-ab8f-feaa3e0b96ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PC_Parameters.py to PC_Parameters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iJoB2KuC4Lz",
        "outputId": "229cf231-49ee-4c68-8b2e-0d0a7e487e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Github/PredictiveCoding/main/Src\n",
            "/content/gdrive/MyDrive/Github/PredictiveCoding/main/Src\n",
            "PC_filters.ipynb    PC_Main_toPytorch.ipynb\t      PC_param.ipynb\n",
            "PC_functions.ipynb  PC_myFunctions.ipynb\t      PC_Step_8_loopJeiJii.ipynb\n",
            "PC_Main.ipynb\t    PC_Optimization_AfterMWE_1.ipynb  PC_StimuliSequence.ipynb\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os, sys #os for global variable\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path_to_module = \"/content/gdrive/MyDrive/Github/PredictiveCoding/main/Src/\"#PC_param.ipynb   #path_to_module = '/content/gdrive/MyDrive/ColabNotebooks/PC_param.ipynb'\n",
        "sys.path.append(path_to_module) # or sys.path.insert(0, path_to_module)\n",
        "\n",
        "#os.symlink('/content/gdrive/MyDrive/Github/PredictiveCoding/main/Src', \"/content/gdrive/MyDrive/Github/PredictiveCoding/main/Src/PC_param.ipynb\")\n",
        "\n",
        "%cd /content/gdrive/MyDrive/Github/PredictiveCoding/main/Src\n",
        "!pwd\n",
        "\n",
        "!ls\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MrR17p1ipoFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # F.mse_loss\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader  # for batch and split Xtrain Ytrain dataset\n",
        "import sys\n",
        "import torchviz\n",
        "import scipy\n",
        "import scipy.ndimage as nd\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "from locale import format\n",
        "from dataclasses import dataclass, MISSING\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "from scipy.interpolate import griddata\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import math\n",
        "# from scipy.sparse import identity\n",
        "from icecream import ic  # for debugging. print variable name\n",
        "\n",
        "## !!!!! To get the parameters\n",
        "#from gdrive.MyDrive.Github.PredictiveCoding.main.Src.PC_param import default_parameters_network\n",
        "\n",
        "#from PC_param import default_parameters_network\n",
        "#import PC_param.ipynb\n",
        "#from PC_Parameters import default_parameters_network\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9DQp7y2sppSr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PC_Parameters import default_parameters_network\n",
        "pars = default_parameters_network()"
      ],
      "metadata": {
        "id": "hoFr9_o4Et1c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "Dht5lPGapvVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 2- Input/Output function\n",
        "\n",
        "def plot_io(x, y, sign):\n",
        "    if sign == \"+\":\n",
        "        sign_name = 'Excitatory'\n",
        "        label = \"ae={0}, be={1}, hme={2}\"\n",
        "        a, b, hm = pars['ae'], pars['be'], pars['hme']\n",
        "        color = \"k\"\n",
        "    elif sign == \"-\":\n",
        "        sign_name = 'Inhibitory'\n",
        "        label = \"ai={0}, bi={1}, hmi={2}\"\n",
        "        a, b, hm = pars['ai'], pars['bi'], pars['hmi']\n",
        "        color = \"r\"\n",
        "\n",
        "    plt.plot(x, y, color, label=label.format(a, b, hm))\n",
        "\n",
        "    plt.xlabel(\"Input values - nA\")\n",
        "    plt.ylabel(\"Spike Frequency - Hz\")\n",
        "    plt.xlim([-0.01, 1])\n",
        "    plt.title(\"Input-output function\")\n",
        "    # plt.title(\"{0} Input-output function\".format(sign_name))\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def plot_r(range_sim, r_e, r_i, param, xlim_ar=None):\n",
        "    label_e = \"Excitatoty  Jee={0}, Jei={1}\"  # , I1={2}\"\n",
        "    label_i = \"Inhibitory  Jii={0}, Jie={1}\"  # , I2={2}\"\n",
        "    plt.plot(range_sim, r_e, \"r\", label=label_e.format(param.Jee, param.Jei))  # , param.I1 #, param.In\n",
        "    plt.plot(range_sim, r_i, \"orange\", label=label_i.format(param.Jii, param.Jie))  # , round(param.I2, 2)))\n",
        "\n",
        "    plt.xlabel(\"Time - ms\")\n",
        "    plt.ylabel(\"Spike Frequency - Hz\")\n",
        "    if xlim_ar != None:\n",
        "        plt.xlim(xlim_ar)  # [0, .1]\n",
        "    plt.title(\"Firing rate of the NMDA and GABA populations\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def plot_s(range_sim, S_e, S_i, param, xlim_ar=None):\n",
        "    label_e = \"Excitatoty  Jee={0}, Jei={1}\"  # , I1={2}\"\n",
        "    label_i = \"Inhibitory  Jii={0}, Jie={1}\"  # , I2={2}\"\n",
        "    plt.plot(range_sim, S_e, \"olive\", label=label_e.format(param.Jee, param.Jei))  # , param.I1\n",
        "    plt.plot(range_sim, S_i, \"green\", label=label_i.format(param.Jii, param.Jie))  # , round(param.I2, 2)\n",
        "    if xlim_ar != None:\n",
        "        plt.xlim(xlim_ar)\n",
        "    plt.xlabel(\"Time - ms\")\n",
        "    plt.ylabel(\"Open channel\")\n",
        "    # plt.xlim([0, .1])\n",
        "    plt.title(\"Average open channel for the NMDA and GABA populations\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "# 2- Plot HeatMap of firing rate function\n",
        "def HeatMap(rE, rI, J=None):\n",
        "    if J == None:\n",
        "        J = [.00989, 0.0081, .1, .87, .00081]  # J = dict(Jin=.008, Jee= .2, Jie=.2, Jei=1.4, Jii=6.7)\n",
        "    if type(J) == dict:\n",
        "        J = np.array(list(J.values()))\n",
        "\n",
        "    rE_df = pd.DataFrame(rE.T)  # to get time vs pop\n",
        "    rI_df = pd.DataFrame(rI.T)\n",
        "    rE_df.index = rE_df.index + 1\n",
        "    rI_df.index = rI_df.index + 1\n",
        "    rE_df.index.name, rI_df.index.name = [\"Excitatory Population\", \"Inhibitory Population\"]\n",
        "    rE_df.columns.name, rI_df.columns.name = [\"Time s\", \"Time s\"]\n",
        "    # print(rE_df.loc[[10]])\n",
        "\n",
        "    # set context for the upcoming plot\n",
        "    sns.set_context(\"notebook\", font_scale=.8, rc={\"lines.linewidth\": 2.5, 'font.family': 'Helvetica'})\n",
        "\n",
        "    fig, (axA, axB) = plt.subplots(2, 1, figsize=(6, 6))\n",
        "\n",
        "    sns.heatmap(rE_df, ax=axA, cmap=\"viridis\")\n",
        "    sns.heatmap(rI_df, ax=axB)\n",
        "    axA.set_title(f\"Firing rate in Hz of exc populations over time. Jie: {J[2]}, Jee: {J[1]}, Jin: {J[0]}\",\n",
        "                  fontdict={\"fontsize\": 10})\n",
        "    axB.set_title(f\"Firing rate in Hz of inh populations over time. Jei: {J[3]}, Jii: {J[4]}\",\n",
        "                  fontdict={\"fontsize\": 10})\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Filters gauss and Dog and LoG\n",
        "def gaussian_filter(s, N):\n",
        "    k = np.arange(1, N + 1)\n",
        "    n = 1 / (np.sqrt(2 * np.pi) * N * s)\n",
        "    gaussW = n * np.exp(-(k - k[:, np.newaxis]) ** 2 / (2 * s ** 2))\n",
        "    gaussW2 = gaussW / (.009 ** 2 / np.max(gaussW))  # 1\n",
        "    return gaussW2\n",
        "\n",
        "\n",
        "def dog_filter(sOut, N):\n",
        "    sIn = sOut / 30\n",
        "    k = np.arange(1, N + 1)\n",
        "    gaussIn = np.exp(-(k - k[:, np.newaxis]) ** 2 / (2 * sIn ** 2))\n",
        "    gaussOut = np.exp(-(k - k[:, np.newaxis]) ** 2 / (2 * sOut ** 2))\n",
        "    dog = gaussOut - gaussIn\n",
        "    if np.max(dog) == 0 or None:\n",
        "        print('zero max')\n",
        "        dog = 0\n",
        "    else:\n",
        "        dog = dog / (.042 ** 2 / np.max(dog))  # .0088\n",
        "    return dog\n",
        "\n",
        "\n",
        "def LoG_filter(s, N):\n",
        "    x_lap = np.eye(N)\n",
        "    lapl_filter = nd.gaussian_laplace(x_lap, sigma=(s, s))\n",
        "    return lapl_filter\n",
        "\n",
        "\n",
        "def dLogGaus(s=.61, N=20):\n",
        "    dig = LoG_filter(s, N) + gaussian_filter(.019 * s, N)\n",
        "    return dig\n",
        "\n",
        "\n",
        "\"\"\"### Differentiable function for back propagation\n",
        "\n",
        "To avoid non-differentiable araising from discontinuity of the function, I \"relax\" (smoothen) the where() expression by using a sigmoid instead\n",
        "*   with grad_fn:\n",
        "*   if I get : > <SumBackward1 object at 0x7f79da0b9520> # differentiable\n",
        "*   else I get none\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def relu_stim(x, stim):\n",
        "    return torch.nn.functional.relu(1.0 - torch.abs(x - stim),\n",
        "                                    inplace=False)  # inplace = False to avoid implace operation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Dirac(A, N=pars[\"NumN\"]):\n",
        "    y = scipy.signal.unit_impulse(N, idx=(torch.max(torch.argmax(A))))  # , dtype= <class 'float'>)\n",
        "    return torch.tensor(y)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"### Try Normalization to \"make it proba\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def make_it_proba(r_e):\n",
        "    \"\"\"sum_r_e = torch.sum(r_e, 1).reshape(r_e.shape[0], 1)\n",
        "    prob_r = torch.div(r_e, sum_r_e)\n",
        "    print(prob_r.grad_fn)\n",
        "    prob_r[prob_r != prob_r] = 0.05\"\"\"  # to replace nan to 1/20 - to sum to 1\n",
        "    # print(\"should sum to 1:\", torch.sum(prob_r, 1)) #to check that it worked\n",
        "    baseline = 1\n",
        "    sum_r_e_and_baseline = torch.sum(r_e, 1).reshape(r_e.shape[0], 1) + baseline\n",
        "    prob_r = torch.div(r_e + baseline, sum_r_e_and_baseline)\n",
        "\n",
        "    return prob_r.reshape(r_e.shape[0], r_e.shape[1])  # log or not log?\n",
        "\n",
        "\n",
        "def make_it_proba_1d(r_e):\n",
        "    baseline = 1\n",
        "    sum_r_e = torch.sum(r_e) + baseline\n",
        "    prob_r = torch.div(r_e +baseline, sum_r_e)  # torch.transpose(r_e, dim0=0 ,dim1=1) poses a problem\n",
        "    #prob_r[prob_r != prob_r] = 0.05  # to replace nan to 1/20 - to sum to 1\n",
        "    print(\"should sum to 1:\", torch.sum(prob_r)) #to check that it worked\n",
        "\n",
        "    return prob_r\n",
        "\n",
        "\n",
        "def log_proba(proba_r):\n",
        "    return torch.log(proba_r)\n",
        "\n",
        "\n",
        "\"\"\"### Try softmax to \"make it proba\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.sum(torch.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "def softmax1D(x):\n",
        "    return torch.exp(x) / torch.sum(torch.exp(x))\n",
        "\n",
        "\"\"\"### Get the expected stimuli : matrix of 1 where stimuli 0 elsewhere\"\"\"\n",
        "\n",
        "\n",
        "# find the stimuli for every X = stim dataset\n",
        "# find the stimuli for every X = stim dataset\n",
        "def get_stimuli_input(X_train_tensor):  # input of the shape Xtrain_tensor[5,:,:]\n",
        "    Xargmax = torch.argmax(X_train_tensor, dim=1)\n",
        "    Xmax = torch.max(Xargmax)\n",
        "    return Xmax\n",
        "\n",
        "def get_stimuli_input1D(X_train_tensor):  # input of the shape Xtrain_tensor[5,:,:]\n",
        "    Xargmax = torch.argmax(X_train_tensor)#, dim=1)\n",
        "    Xmax = torch.max(Xargmax)\n",
        "    return Xmax\n",
        "\n",
        "\n",
        "# replace where function by relu functio which is differentiable\n",
        "def get_expected_Y_relu(X_train_tensor):\n",
        "    x_t = torch.transpose(X_train_tensor, 0, 1)\n",
        "    dirac_2d = torch.zeros(x_t.shape)\n",
        "    stim = get_stimuli_input(\n",
        "        X_train_tensor)  # input of the shape Xtrain_tensor[5,:,:] # here get_stimuli not differenciable\n",
        "\n",
        "    for pop, t in enumerate(x_t):\n",
        "        tpop = torch.tensor(pop)\n",
        "        dirac_2d[pop, :] = torch.nn.functional.relu(1.0 - torch.abs(tpop - stim), inplace=False).requires_grad_(False)\n",
        "    dirac_2d = torch.transpose(dirac_2d, 1, 0)\n",
        "    return dirac_2d\n",
        "\n",
        "\n",
        "def get_expected_Y_relu_1d_where(X_train_tensor):\n",
        "    stim = get_stimuli_input1D(X_train_tensor)\n",
        "    dirac_1d = torch.zeros(X_train_tensor.shape)\n",
        "    # Calculate the difference between tpop and stim\n",
        "    for pop in enumerate(X_train_tensor):\n",
        "        dirac_1d[pop[0]] = torch.where(pop[0] == torch.tensor(stim), torch.tensor(1.0), torch.tensor(0.0)).requires_grad_(False)#true #not differenciable\n",
        "    return dirac_1d\n",
        "\n"
      ],
      "metadata": {
        "id": "TtML8XGSptv2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "o3oROWSKFJPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Classes"
      ],
      "metadata": {
        "id": "e0DyLbiAFKpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "*\n",
        "*\n",
        "***********  CLASS\n",
        "*\n",
        "*\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ***************** CLASS ***************************************\n",
        "\n",
        "@dataclass\n",
        "class Parameter:\n",
        "    # °°° Load the parameters °°°\n",
        "\n",
        "    taue: float = pars[\"taue\"]\n",
        "    ae: float = pars['ae']\n",
        "    be, hme, I_noise = pars['be'], pars['hme'], pars['I_noise']\n",
        "    Jee: float = pars['Jee']\n",
        "    taui, ai, bi, hmi = pars['taui'], pars['ai'], pars['bi'], pars['hmi']\n",
        "    Jii: float = pars['Jii']\n",
        "    Jei: float = pars['Jei']\n",
        "    Jie: float = pars['Jie']\n",
        "    Jes, Jsi = pars['Jes'], pars['Jsi']\n",
        "    Jiq: float = pars['Jiq']  # 0.85; #nA\n",
        "    Jin: float = pars['Jin']\n",
        "    tauNMDA, tauAMPA, tauGABA = pars['tauNMDA'], pars['tauAMPA'], pars['tauGABA']\n",
        "    gamma: float = pars['gamma']  # nmda coupling parameter from brunel\n",
        "    c_dash = pars['c_dash']\n",
        "    sigma = pars['sigma']  # param.sigma = .0007 for Noise\n",
        "    I_noise = pars['sigma'] * np.random.randn(3, 1)\n",
        "    I1 = pars['Jext'] * pars['mu0'] * (1 + pars['c_dash'] / 100)\n",
        "    I2 = pars['Jext'] * pars['mu0'] * (1 - pars['c_dash'] / 100)\n",
        "    # I1, I2 = pars['I1'], pars['I2']\n",
        "\n",
        "    sigmaIn = pars['sigmaIn']\n",
        "\n",
        "    # Input parameters\n",
        "    In0 = pars['In0']  # % Spontaneous firing rate of input populations (Hz)\n",
        "    InMax = pars['InMax']  # % Max firing rate of input populations (Hz)\n",
        "    Iq0 = pars['Iq0']  # % Spontaneous firing rate of feedback populations (Hz)\n",
        "    IqMax = pars['IqMax']  # % Max firing rate of feedback populations (Hz)\n",
        "\n",
        "    # Gaussian filter\n",
        "    # sIn = pars['sigmaInh'][0]\n",
        "    # sOut = pars['sigmaInh'][1]\n",
        "\n",
        "    def __init__(self, sEI, sIn, sOut, N):  # sEI=4, sIn=.2, sOut=1.2,\n",
        "        # Weights (from gaussian filter)\n",
        "        self.N = N  # pars['NumN']\n",
        "        self.wei = torch.tensor(dog_filter(sOut, int(N)), dtype=torch.float32)   # .astype( torch.float32))  # , dtype='float64'# fun.dLogGaus(.61, N)  #fun.dog_filter(sIn, sOut, N)#gaussian_filter(sEI, N)\n",
        "        self.wii = torch.tensor(np.eye(int(N)), dtype=torch.float32) #.astype(torch.float32))  # dog_filter(sIn, sOut, N)#np.eye(N) #\n",
        "        self.wie = torch.tensor(gaussian_filter(sEI, int(N)), dtype=torch.float32) #.astype(torch.float32))  # dog_filter(sIn, sOut, N)\n",
        "        self.wes = torch.tensor(np.eye(int(N)), dtype=torch.float32)  #.astype(torch.float32))  # Identity matrix\n",
        "        self.f = np.arange(1, N + 1)\n",
        "        self.sEI = sEI\n",
        "        self.sIn = sIn\n",
        "        self.sOut = sOut\n",
        "\n",
        "    def reset(self):  # https://stackoverflow.com/questions/56878667/setting-default-values-in-a-class\n",
        "\n",
        "        for name, field in self.__dataclass_fields__.items():\n",
        "            if field.default != MISSING:\n",
        "                setattr(self, name, field.default)\n",
        "            else:\n",
        "                setattr(self, name, field.default_factory())\n",
        "\n",
        "\n",
        "# °°° Time of the simulation °°°\n",
        "class Simulation:\n",
        "    def __init__(self, dt, T):\n",
        "        self.dt = dt\n",
        "        self.T = T\n",
        "        self.range_t = (np.arange(0, self.T, self.dt))\n",
        "        self.Lt = self.range_t.size\n",
        "\n",
        "    def printSim(self):\n",
        "        print(\"T time step of the simulation (dt): \", self.dt, \"  Duration of simulation S (T): \", self.T,\n",
        "              \"Length of the time frame (Lt): \", self.Lt)\n",
        "\n",
        "\n",
        "#  °°° Initialisation of the variables °°°\n",
        "\n",
        "class Stim:\n",
        "    def __init__(self, param, simu, f, ISI=1, dur=0.2):  # 8 #[10]\n",
        "        self.f = f  # array of frequency stimulus types\n",
        "        self.ISI = ISI  # inter-stimulus interval\n",
        "        self.dur = dur  # duration in s of a specific stimulus segment . The time the frequency fi ll be maintained in the f array\n",
        "        self.tail = 0\n",
        "        self.predDt = 0\n",
        "        self.pred = 0\n",
        "        self.InMax = param.InMax\n",
        "        self.In0 = param.In0\n",
        "\n",
        "        # Instantaneous frequency\n",
        "        f_instant = np.zeros((int(self.ISI / simu.dt) + 1, 1))  # size ISI : 1 /dt : 1000\n",
        "\n",
        "        for fx in self.f:\n",
        "            fx_array = np.concatenate((np.ones((int(self.dur / simu.dt), 1)) * fx,\n",
        "                                       # just 1 frequency of 8 . # inter-stim interval is aslong as stim interval\n",
        "                                       np.zeros((int(self.ISI / simu.dt),\n",
        "                                                 1))))  # so I get 1 list with 1000 lists containing 8 and 1000 lists containing 0\n",
        "        f_stim = np.vstack((f_instant, fx_array))  # stack vertically these arrays # [0] *1000 , [8]*1000, [0]*1000\n",
        "        self.f_stim = f_stim[1:]  # 1400*1\n",
        "\n",
        "    # bottom up sensory Input # duration 1sec\n",
        "    def sensoryInput(self, parameter, simu, sigmaIn=None, paramf=None, f_stim=None, InMax=None, In0=None):\n",
        "        # paramf = np.arange(1, 101)\n",
        "        w = np.exp(-(((paramf or parameter.f) - (f_stim or self.f_stim)) ** 2) / (\n",
        "                2 * (sigmaIn or parameter.sigmaIn) ** 2))  # pars['f'] = 1:N\n",
        "\n",
        "        # totalAct = w.sum(axis = 1) #sum over each row\n",
        "        # norm_w = (w.T / totalAct).T # elementwise division\n",
        "        In = np.where(f_stim or self.f_stim > 0, (InMax or self.InMax) * w + (In0 or self.In0),\n",
        "                      0)  # if stim >0 give InMax * weight + In0 otherwise give 0\n",
        "        if self.tail != 0:\n",
        "            tail_zeros = np.zeros((parameter.N, int(self.tail / simu.dt)))\n",
        "            In = np.hstack((In, tail_zeros))\n",
        "\n",
        "        range_sim = np.arange(1, In.shape[0] + 1)\n",
        "        self.In = In\n",
        "        self.w = w\n",
        "        self.sigmaIn = sigmaIn\n",
        "\n",
        "        return In, range_sim, w, sigmaIn\n",
        "\n",
        "    def printStim(self):\n",
        "        print(\"frequence of stimulus f:\", self.f, \"  ISI:\", self.ISI, \" Size In:\", self.In.shape, \"Size w:\",\n",
        "              self.w.shape, \"  f_stim:\", self.f_stim.shape,\n",
        "              \"sigmaIn:\", self.sigmaIn)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rIQe8vT3FML_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Model"
      ],
      "metadata": {
        "id": "J_6Z0lXJFNiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "*\n",
        "*\n",
        "***********  CLASS MYMODEL\n",
        "*\n",
        "*\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MyModel_time(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel_time, self).__init__()\n",
        "\n",
        "        #--- Define other model parameters, layers, or components here if needed\n",
        "        self.dt = torch.tensor(1e-4) #sim.dt\n",
        "        self.N = 20\n",
        "        self.taue = self.taui = torch.tensor(0.005)\n",
        "         # ¤ parameter of the phi function Not tweakable parameters\n",
        "        self.ae = torch.tensor(18.26)  # 2 #Wong have to check # Modelling and Meg Gain of the E populaiton\n",
        "        self.be = torch.tensor(-5.38)  # Threshold of the E populaiton\n",
        "        self.hme = torch.tensor(78.67)\n",
        "        self.ai = torch.tensor(21.97)\n",
        "        self.bi = torch.tensor(-4.81)\n",
        "        self.hmi = torch.tensor(125.62)\n",
        "        #create the smallest possible number\n",
        "        self.epsilon = sys.float_info.epsilon\n",
        "\n",
        "        self.sIn = torch.tensor(.1)\n",
        "        self.sOut= 3.\n",
        "        self.sEI = .2\n",
        "        self.tauAMPA = torch.tensor(0.002)\n",
        "        self.tauGABA = torch.tensor(0.005)\n",
        "\n",
        "        self.wei = torch.tensor(dog_filter(self.sOut, int(self.N)), dtype=torch.float32)\n",
        "        self.wii = torch.tensor(np.eye(int(self.N)), dtype=torch.float32) # dog_filter(sIn, sOut, N)#np.eye(N) #\n",
        "        self.wie = torch.tensor(gaussian_filter(self.sEI, int(self.N)), dtype=torch.float32) #.astype(torch.float32))  # dog_filter(sIn, sOut, N)\n",
        "        self.wes = torch.tensor(np.eye(int(self.N)), dtype=torch.float32)  # Identity matrix\n",
        "\n",
        "        self.Jee = nn.Parameter(torch.tensor(0.072, requires_grad= True, dtype= torch.float64))#, requires_grad=False, dtype=torch.float32)#I replaced .072 by 0.072\n",
        "        #ic(self.Jee.grad_fn) #should be none\n",
        "        self.Jei = nn.Parameter(torch.tensor(0.004, requires_grad= True, dtype= torch.float64))\n",
        "        self.Jie = nn.Parameter(torch.tensor(0.05, requires_grad=True, dtype=torch.float64))\n",
        "        self.Jii = nn.Parameter(torch.tensor(0.6, requires_grad=True, dtype=torch.float64))\n",
        "        self.Jin = nn.Parameter(torch.tensor(0.00695, requires_grad= True, dtype=torch.float64))\n",
        "\n",
        "    def phi(self, I_tot, a, b, hm): #)))  # this use a lot of memory - exponential part\n",
        "        #multi= torch.nan_to_num((torch.mul(a, I_tot) + b), nan = self.epsilon, posinf=140, neginf=self.epsilon)\n",
        "\n",
        "        for i in range(I_tot.shape[0]):\n",
        "                if torch.isnan(I_tot[i])== True:\n",
        "                    ic(I_tot, i)\n",
        "                    exit()\n",
        "\n",
        "        mulan =torch.mul(a, I_tot)\n",
        "\n",
        "        multi= mulan + b\n",
        "\n",
        "        expo = torch.exp(- (multi))  #.abs()+ self.epsilon)\n",
        "        return torch.multiply(hm, torch.divide(1, (1+ expo)))\n",
        "\n",
        "    def forward(self, In):\n",
        "        #--- Initialize model variables here\n",
        "        prev_r_e = torch.zeros((In.shape[0], self.N)) # torch.ones(self.N) shows more obvious results\n",
        "        prev_r_i = torch.zeros((In.shape[0], self.N))\n",
        "        prev_s_ampa = torch.zeros((In.shape[0], self.N))\n",
        "        prev_s_gaba = torch.zeros((In.shape[0], self.N))\n",
        "        s_ampa = torch.tensor(0.)\n",
        "        i_tot_e = torch.tensor(0.)\n",
        "        i_tot_i = torch.tensor(0.)\n",
        "\n",
        "        for k in range(1, In.shape[0]):\n",
        "            #--- Compute values of interest\n",
        "            #the operation Jee_re = self.Jee * prev_r_e => triggers inplace error\n",
        "            s_gaba_wie = prev_s_gaba[k-1,:] @ self.wie\n",
        "            s_ampa_wei = prev_s_ampa[k-1,:] @ self.wei\n",
        "            s_gaba_wii = prev_s_gaba[k-1,:] @ self.wii\n",
        "            JeeAmpa =  torch.mul(self.Jee, s_ampa)\n",
        "            i_tot_e = torch.add(torch.subtract(JeeAmpa, torch.mul(self.Jie, s_gaba_wie)), torch.mul(self.Jin, In[k - 1, :]))\n",
        "            i_tot_i = torch.subtract(torch.mul(self.Jei, s_ampa_wei), torch.mul(self.Jii, s_gaba_wii))\n",
        "\n",
        "            phi_arr_e = self.phi(i_tot_e, self.ae, self.be, self.hme)\n",
        "            phi_arr_i = self.phi(i_tot_i, self.ai, self.bi, self.hmi)\n",
        "\n",
        "            dr_e_dt = (-prev_r_e[k - 1, :] + phi_arr_e) / self.taue\n",
        "            dr_i_dt = (-prev_r_i[k - 1, :] + phi_arr_i) / self.taui\n",
        "\n",
        "            r_e = prev_r_e[k - 1, :] + dr_e_dt * self.dt\n",
        "            r_i = prev_r_i[k - 1, :] + dr_i_dt * self.dt\n",
        "\n",
        "            dS_amp_dt = (- prev_s_ampa[k - 1, :] / self.tauAMPA) + r_e\n",
        "            s_ampa = prev_s_ampa[k - 1, :] + dS_amp_dt * self.dt\n",
        "\n",
        "            dS_gab_dt = (- prev_s_gaba[k - 1, :] / self.tauGABA) + r_i\n",
        "            s_gaba = prev_s_gaba[k - 1, :] + dS_gab_dt * self.dt\n",
        "\n",
        "            prev_r_e[k,:] = r_e\n",
        "            prev_r_i[k,:] = r_i\n",
        "            prev_s_ampa[k,:] = s_ampa\n",
        "            prev_s_gaba[k,:] = s_gaba\n",
        "\n",
        "\n",
        "            dr_e_dt = torch.div(torch.add(torch.neg(prev_r_e[k-1,:]), phi_arr_e), self.taue)\n",
        "            dr_i_dt = torch.div(torch.add(torch.neg(prev_r_i[k-1,:]), phi_arr_i), self.taui)\n",
        "            #ic(dr_e_dt.grad_fn)\n",
        "\n",
        "            r_e = torch.mul(torch.add(torch.neg(prev_r_e[k-1,:]), dr_e_dt), self.dt)# torch.multiply(), self.newfactor)\n",
        "            #ic(r_e.grad_fn, r_e.shape)\n",
        "            r_i = torch.mul(torch.add(torch.neg(prev_r_i[k-1,:]), dr_i_dt), self.dt)\n",
        "\n",
        "\n",
        "            dS_amp_dt = torch.add(torch.divide(- prev_s_ampa[k-1,:], self.tauAMPA), r_e)\n",
        "            s_ampa = torch.mul(torch.add(prev_s_ampa[k-1,:], dS_amp_dt), self.dt)\n",
        "            #ic(dS_amp_dt.grad_fn, s_ampa.grad_fn)\n",
        "            dS_gab_dt = torch.add(torch.divide(- prev_s_gaba[k-1,:], self.tauGABA), r_i)\n",
        "            s_gaba = torch.mul(torch.add(prev_s_gaba[k-1,:], dS_gab_dt), self.dt)\n",
        "\n",
        "\n",
        "        return prev_r_e, prev_r_i\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d9VxVkI6FSo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create stimuli Input"
      ],
      "metadata": {
        "id": "-R88oSVXFTVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "*\n",
        "*  Creat IN and Forward pass\n",
        "*\n",
        "*\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    ## Parameters used to create In\n",
        "N = 20\n",
        "# \\\\\\\\\\\\\\\\\\\\\\ Parameters\n",
        "param = Parameter(N=20, sIn=.1, sOut=3., sEI=.2)\n",
        "# \\\\\\\\\\\\\\\\\\\\\\ Simulation time\n",
        "simu = Simulation(1e-4, .4)  # dt #rangeSim #dur = 2s\n",
        "\n",
        "# \\\\\\\\\\\\\\\\\\\\\\ Bottom up sensory input\n",
        "stimuli = Stim(param, simu, dur=.3, f=[8], ISI=.05)  # dur = 1s Isi=1s\n",
        "In, range_sim, w, sigmaIn = stimuli.sensoryInput(param, simu, sigmaIn=2.)\n",
        "\n",
        "J1 = {'Jee': 0.072, 'Jei': 0.004, 'Jie': 0.05, 'Jii': 0.6, 'Jin': 0.00695}\n",
        "J_list = list(J1.keys())\n",
        "\n",
        "# +++++++++++++++++++++++++ Initialize the Model ++++++++++++++++++++++++++++\n",
        "mymodel = MyModel_time()\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN forward pass and Print heatmap ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "sti = torch.tensor(stimuli.In, dtype=torch.float32)\n",
        "r_e, r_i = mymodel.forward(sti)\n",
        "print(torch.max(r_e[1000,:]))\n",
        "HeatMap(r_e.detach().numpy(), r_i.detach().numpy(), J1)\n",
        "HeatMap(sti.detach().numpy(), r_i.detach().numpy(), J1)"
      ],
      "metadata": {
        "id": "U-Xs-oU-FY2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization part"
      ],
      "metadata": {
        "id": "YlZSpYE2FcRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVeeTCr5c432"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "*\n",
        "*  OPTIMIZATION PART\n",
        "*\n",
        "*\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# +++++++++++++++++++++++++ Optimizer ++++++++++++++++++++++++++++\n",
        "learning_rate = 0.00001 #0.001\n",
        "optimizer = optim.SGD(mymodel.parameters(),\n",
        "                      lr=learning_rate, weight_decay = 0.0001)#, weight_decay = 0.00001) #, weight_decay = 0.00001)#, weight_decay = 0.001)#0.989\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++++++++++++++ Epochs +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "num_epochs = 5\n",
        "\n",
        "# +++++++++++++++++++++++++ Inputs + Labels +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "X_input = sti\n",
        "Y_target = get_expected_Y_relu(X_input) #get the expected dirac delta for our particular Input\n",
        "losses = torch.zeros(num_epochs) # used to plot the loss at the end\n",
        "\n",
        "# +++++++++++++++++++++++++ Problems investigations +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# import tracemalloc\n",
        "# tracemalloc.start()\n",
        "mymodel.train()\n",
        "criterion = nn.CrossEntropyLoss()#.cuda()\n",
        "\n",
        "# +++++++++++++++++++++++++ Optimization loop +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "with torch.autograd.set_detect_anomaly(False):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Create a new input tensor for each epoch\n",
        "        #X_input.requires_grad = False\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # calculate output\n",
        "        Y_prediction, I = mymodel(X_input)\n",
        "        #ic(Y_prediction.grad_fn)\n",
        "\n",
        "        # calculate loss\n",
        "        Y_prediction_prob = make_it_proba(Y_prediction)\n",
        "        #loss = torch.sum(torch.sum((Y_prediction_prob-Y_target), axis =1))# (torch.mean((Y_prediction_prob - Y_target)**2))\n",
        "        loss = criterion(Y_prediction_prob, Y_target) #t\n",
        "\n",
        "        #ic(loss.grad_fn)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        #torch.nn.utils.clip_grad_norm_(mymodel.parameters(), -5, 5)  # Adjust max_norm as needed\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        losses[epoch] = loss\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss}, Loss_grad: {loss.grad_fn}')  # .item()\n",
        "        for i, par in enumerate(mymodel.parameters()):\n",
        "           ic(J_list[i], par, par.grad)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "*\n",
        "*  Plot the loss over epochs\n",
        "*\n",
        "\"\"\"\n",
        "\n",
        "plt.plot(np.arange(losses.shape[0]), losses.detach().numpy(), 'bo', label='Training loss')\n",
        "\n",
        "plt.title(f\"Loss over {num_epochs} epochs for a learning rate of {learning_rate}\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# check if input has zeros\n",
        "#torch.all(losses) # return True if there are zeros, otherwise return False\n",
        "\n",
        "# check if input has nans\n",
        "#torch.any(torch.isnan(losses)) # return True if there are nans, otherwise return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4dmzDl4FFFDf"
      }
    }
  ]
}