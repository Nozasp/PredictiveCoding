def custom_loss_(Prediction,Inhib, Target, derivativeE):
  #1/ Proba term
  criterion = torch.nn.NLLLoss()
  P2 = make_it_proba(Prediction) #
  loss_norm = criterion(P2, Target.long())

  #2/ derivative good 
  eps = torch.FloatTensor([sys.float_info.epsilon]) 
  Target_idx_np = (Target).numpy().astype(int)
  loss_derivative = torch.zeros_like(Target)
  

  # L1
  hyperactvity_penalty = torch.zeros(train_IN.shape[0])
  laziness_penalty = torch.zeros(train_IN.shape[0])
  
  count = 0
  i2 = 0
  start = 0
  stop = (len_sim)
  for i, sti_idx in enumerate(Target_idx_np):
      count +=1
      if count == stop:
          time_idx = slice(start, stop)
          
          
          if torch.max(Prediction[time_idx,sti_idx]) > 60.: #60
              hyperactvity_penalty[i2] = torch.sum((Prediction[time_idx, sti_idx]**2))
          else:
              hyperactvity_penalty[i2] = 0
      
          if torch.max(Prediction[time_idx,sti_idx]) < 10.: #60
              laziness_penalty[i2] = torch.sum(1 / torch.clamp(Prediction[time_idx, sti_idx]**2, min = eps)) #torch.clamp(r_e[:, 7], max=10.0

          else:
              laziness_penalty[i2] = 0
  
          
          i2 += 1
          start = stop
          stop += len_sim

  len_sim_test = len_sim
  count = 0
  start = 0
  for i, sti_idx in enumerate(Target_idx_np):
    count += 1
    if count == len_sim_test:
        loss_derivative[i] = - F.softplus(derivativeE[start:len_sim_test,sti_idx] ).sum() + F.softplus(derivativeE[start:len_sim_test,:sti_idx]).sum() + F.softplus(derivativeE[start:len_sim_test,(sti_idx+1):]).sum()
        #ic(loss_derivative[i])
        start = count
        len_sim_test += len_sim_test
  """
  for i, sti_idx in enumerate(Target_idx_np):
    loss_derivative[i] = - F.softplus(derivativeE[:,sti_idx] ).sum() + F.softplus(derivativeE[:,:sti_idx]).sum() + F.softplus(derivativeE[:,(sti_idx+1):]).sum()
  """
  loss_derivative_term = loss_derivative.mean()
  coef_derivative = 1E-6 #1E-6 #0.00001
  loss_derivative_term = coef_derivative * loss_derivative_term
  
  hyperactvity_penalty_term = hyperactvity_penalty.mean()
  hyperactvity_penalty_coef= 1E-8#1E-7#1E-6 1E-6
  hyperactvity_penalty_term = hyperactvity_penalty_term * hyperactvity_penalty_coef
  laziness_penalty = (laziness_penalty.sum() * 0.01)

  #4/ Constraint ws and Js
  parm = {}
  for name, par in model.named_parameters() : # enumerate(trained_model.parameters()):
        parm[name] = par 

  be_positive = 0
  param_l = list(parm.items())
  for i in range(len(param_l)):
      be_positive += sum_relu(param_l[i][1]) 

   
  # Sparse coding 
  sparse_coding_coef = 1E-4
  tau_s = 1#0.001
  sparse_coding_wei = sparse_coding_coef *  torch.sum(torch.log(1 + (parm["wei"]**2 / tau_s)))#torch.sum(torch.abs(W["wei"])) #)#torch.sum(torch.abs(Inhib))
  sparse_coding_wie = sparse_coding_coef * torch.sum(torch.log(1 + (parm["wie"]**2 / tau_s))) #torch.sum(torch.abs(W["wie"]))##torch.sum(torch.abs(Inhib))
  sparse_coding_term =  (sparse_coding_wei + sparse_coding_wie) # + sparse_coding_wii+ sparse_coding_wee +   sparse_coding_coef *
  
  
  #deincentivate long range connection: 
  # Compute the distance of each cell from the diagonal
  distances = np.abs(np.arange(param.N)[np.newaxis, :] - np.arange(param.N)[:, np.newaxis])
  distance_coef = 1E-3#1E-2
  cost_distances_inh = parm["wie"] * torch.tensor(distances)
  cost_distance_inh_scalar = torch.sum(cost_distances_inh) * distance_coef 

  
  Cost = loss_norm + loss_derivative_term + cost_distance_inh_scalar + (be_positive *10) + hyperactvity_penalty_term + laziness_penalty + sparse_coding_term #+ activity_regularization

  #ic(loss_norm, loss_derivative_term, be_positive,cost_distance_inh_scalar, sparse_coding_term, hyperactvity_penalty_term, laziness_penalty)#loss_derivative_term, hyperactvity_penalty_term)
  return Cost